import streamlit as st
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image

# ---------------- ëª¨ë¸ ì •ì˜ ----------------
class MyConvBlock(nn.Module):
    def __init__(self, in_ch, out_ch, dropout_p):
        super().__init__()
        self.model = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(),
            nn.Dropout(dropout_p),
            nn.MaxPool2d(2, stride=2)
        )
    def forward(self, x):
        return self.model(x)

IMG_CHS = 1
IMG_WIDTH, IMG_HEIGHT = 28, 28
N_CLASSES = 24

class ASLModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            MyConvBlock(IMG_CHS, 25, 0.0),
            MyConvBlock(25, 50, 0.2),
            MyConvBlock(50, 75, 0.0),
            nn.Flatten(),
            nn.Linear(75 * 3 * 3, 512),
            nn.Dropout(0.3),
            nn.ReLU(),
            nn.Linear(512, N_CLASSES)
        )
    def forward(self, x):
        return self.net(x)

# ---------------- ì„¤ì • ë° ëª¨ë¸ ë¡œë“œ ----------------
label_map = {i: chr(ord('A') + i) for i in range(24) if i != 9}  # J, Z ì œì™¸
label_map = dict(enumerate([c for c in label_map.values()]))

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model_path = './asl_cnn_model.pth'
model = torch.load(model_path, map_location=device)
model.to(device)
model.eval()

# ---------------- ì „ì²˜ë¦¬ í•¨ìˆ˜ ----------------
def center_square_crop(image_pil):
    width, height = image_pil.size
    min_dim = min(width, height)
    left = (width - min_dim) // 2
    top = (height - min_dim) // 2
    return image_pil.crop((left, top, left + min_dim, top + min_dim))

def preprocess_image(image_pil):
    image_cropped = center_square_crop(image_pil)
    # ì •ì ì¸ transform ë§Œ ì ìš©í•¨
    transform = transforms.Compose([
        transforms.Grayscale(),
        transforms.Resize((IMG_WIDTH, IMG_HEIGHT)),
        transforms.ToTensor()
    ])
    return transform(image_cropped), image_cropped

# ---------------- Streamlit UI ----------------
st.title("ğŸ¤Ÿ ASL ì•ŒíŒŒë²³ ì˜ˆì¸¡ê¸°")
st.write("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ ì¹´ë©”ë¼ë¡œ ì´¬ì˜í•˜ì—¬ ì† ëª¨ì–‘ì„ ì˜ˆì¸¡í•´ë³´ì„¸ìš”.")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
st.session_state.setdefault("prediction_result", None)

# íƒ­ êµ¬ë¶„
tab1, tab2 = st.tabs(["ğŸ“ ì´ë¯¸ì§€ ì—…ë¡œë“œ", "ğŸ“¸ ì¹´ë©”ë¼ ì´¬ì˜"])

input_image = None

# ì—…ë¡œë“œ íƒ­
with tab1:
    uploaded_file = st.file_uploader("ASL ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=['png', 'jpg', 'jpeg'], key="upload_input")
    if uploaded_file is not None:
        input_image = Image.open(uploaded_file).convert("RGB")
    else:
        st.session_state.prediction_result = None

# ì¹´ë©”ë¼ íƒ­
with tab2:
    camera_image = st.camera_input("ì¹´ë©”ë¼ë¡œ ì† ëª¨ì–‘ì„ ì´¬ì˜í•˜ì„¸ìš”", key="camera_input")
    if camera_image is not None:
        input_image = Image.open(camera_image).convert("RGB")
    else:
        st.session_state.prediction_result = None

# ì´ë¯¸ì§€ í‘œì‹œ ë° ì˜ˆì¸¡
if input_image is not None:
    cropped_image = center_square_crop(input_image)
    col1, col2 = st.columns(2)
    with col1:
        st.image(input_image, caption="ğŸ“¸ ì›ë³¸ ì´ë¯¸ì§€", use_container_width=True)
        st.write(f"ì›ë³¸ í¬ê¸°: {input_image.size[0]}Ã—{input_image.size[1]}")
    with col2:
        st.image(cropped_image, caption="âœ‚ ì¤‘ì•™ Crop ì´ë¯¸ì§€", use_container_width=True)
        st.write(f"Crop í¬ê¸°: {cropped_image.size[0]}Ã—{cropped_image.size[1]}")

    if st.button("Predict"):
        img_tensor, _ = preprocess_image(input_image)
        img_tensor = img_tensor.unsqueeze(0).to(device)

        with torch.no_grad():
            outputs = model(img_tensor)
            probs = torch.softmax(outputs, dim=1)
            topk_probs, topk_indices = torch.topk(probs, 3)

        result_lines = []
        for i in range(3):
            idx = int(topk_indices[0][i])
            if idx in label_map:
                label = label_map[idx]
                prob = float(topk_probs[0][i]) * 100
                result_lines.append(f"{i+1}. **{label}** ({prob:.2f}%)")

        st.session_state.prediction_result = result_lines

# ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥
if st.session_state.prediction_result:
    for line in st.session_state.prediction_result:
        st.success(line)